/**
 * AI Chat API 调用模块
 * 支持多个AI平台的API调用和流式输出
 */

export interface MessageAttachment {
    type: 'image' | 'file';
    name: string;
    data: string; // base64 或 URL
    mimeType?: string;
}

export interface MessageContent {
    type: 'text' | 'image_url';
    text?: string;
    image_url?: {
        url: string;
    };
}

export interface Message {
    role: 'user' | 'assistant' | 'system';
    content: string | MessageContent[];
    attachments?: MessageAttachment[];
    thinking?: string; // 思考过程内容
}

export interface ChatOptions {
    apiKey: string;
    model: string;
    messages: Message[];
    temperature?: number;
    maxTokens?: number;
    stream?: boolean;
    onChunk?: (chunk: string) => void;
    onComplete?: (fullText: string) => void;
    onError?: (error: Error) => void;
    signal?: AbortSignal; // 用于中断请求
    enableThinking?: boolean; // 是否启用思考模式
    onThinkingChunk?: (chunk: string) => void; // 思考过程回调
    onThinkingComplete?: (thinking: string) => void; // 思考完成回调
}

export interface ModelInfo {
    id: string;
    name: string;
    provider: string;
}

export type AIProvider = 'gemini' | 'deepseek' | 'openai' | 'volcano' | 'custom';

interface ProviderConfig {
    name: string;
    baseUrl: string;
    modelsEndpoint: string;
    chatEndpoint: string;
    apiKeyHeader: string;
}

// 预定义的AI平台配置
const PROVIDER_CONFIGS: Record<AIProvider, ProviderConfig> = {
    gemini: {
        name: 'Gemini',
        baseUrl: 'https://generativelanguage.googleapis.com',
        modelsEndpoint: '/v1beta/models',
        chatEndpoint: '/v1beta/models/{model}:streamGenerateContent',
        apiKeyHeader: 'x-goog-api-key'
    },
    deepseek: {
        name: 'DeepSeek',
        baseUrl: 'https://api.deepseek.com',
        modelsEndpoint: '/v1/models',
        chatEndpoint: '/v1/chat/completions',
        apiKeyHeader: 'Authorization'
    },
    openai: {
        name: 'OpenAI',
        baseUrl: 'https://api.openai.com',
        modelsEndpoint: '/v1/models',
        chatEndpoint: '/v1/chat/completions',
        apiKeyHeader: 'Authorization'
    },
    volcano: {
        name: '火山引擎',
        baseUrl: 'https://ark.cn-beijing.volces.com',
        modelsEndpoint: '/api/v3/models',
        chatEndpoint: '/api/v3/chat/completions',
        apiKeyHeader: 'Authorization'
    },
    custom: {
        name: 'Custom',
        baseUrl: '',
        modelsEndpoint: '/v1/models',
        chatEndpoint: '/v1/chat/completions',
        apiKeyHeader: 'Authorization'
    }
};

/**
 * 标准化API地址
 * @param url 用户输入的API地址
 * @returns 标准化后的地址和是否强制使用
 */
function normalizeApiUrl(url: string): { url: string; force: boolean } {
    if (!url) return { url: '', force: false };

    const force = url.endsWith('#');
    url = url.replace(/#$/, '');

    // 移除末尾的斜杠
    url = url.replace(/\/$/, '');

    // 如果不是强制使用，移除 /v1
    if (!force) {
        url = url.replace(/\/v1$/, '');
    }

    return { url, force };
}

/**
 * 获取模型列表
 */
export async function fetchModels(
    provider: string,
    apiKey: string,
    customApiUrl?: string
): Promise<ModelInfo[]> {
    // 检查是否是内置平台
    const builtInProviders: Record<string, boolean> = {
        gemini: true,
        deepseek: true,
        openai: true,
        volcano: true
    };

    let config: ProviderConfig;
    let baseUrl: string;

    if (builtInProviders[provider]) {
        config = PROVIDER_CONFIGS[provider as AIProvider];
        baseUrl = config.baseUrl;

        if (provider === 'custom' && customApiUrl) {
            const normalized = normalizeApiUrl(customApiUrl);
            baseUrl = normalized.url;
        }
    } else {
        // 自定义平台
        if (!customApiUrl) {
            throw new Error('Custom provider requires API URL');
        }

        const normalized = normalizeApiUrl(customApiUrl);
        baseUrl = normalized.url;
        config = {
            name: 'Custom',
            baseUrl: baseUrl,
            modelsEndpoint: '/v1/models',
            chatEndpoint: '/v1/chat/completions',
            apiKeyHeader: 'Authorization'
        };
    }

    const url = `${baseUrl}${config.modelsEndpoint}`;

    try {
        const headers: Record<string, string> = {
            'Content-Type': 'application/json'
        };

        // 处理不同平台的认证方式
        if (provider === 'gemini') {
            headers[config.apiKeyHeader] = apiKey;
        } else {
            headers[config.apiKeyHeader] = `Bearer ${apiKey}`;
        }

        const response = await fetch(url, {
            method: 'GET',
            headers
        });

        if (!response.ok) {
            throw new Error(`Failed to fetch models: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();

        // 处理不同平台的响应格式
        if (provider === 'gemini') {
            return (data.models || []).map((model: any) => ({
                id: model.name.replace('models/', ''),
                name: model.displayName || model.name,
                provider: config.name
            }));
        } else {
            return (data.data || []).map((model: any) => ({
                id: model.id,
                name: model.id,
                provider: config.name
            }));
        }
    } catch (error) {
        console.error('Error fetching models:', error);
        throw error;
    }
}

/**
 * 发送聊天请求 (OpenAI 格式)
 */
async function chatOpenAIFormat(
    baseUrl: string,
    apiKey: string,
    endpoint: string,
    options: ChatOptions
): Promise<void> {
    const url = `${baseUrl}${endpoint}`;

    // 转换消息格式以支持多模态
    const formattedMessages = options.messages.map(msg => ({
        role: msg.role,
        content: msg.content
    }));

    const requestBody: any = {
        model: options.model,
        messages: formattedMessages,
        temperature: options.temperature || 0.7,
        max_tokens: options.maxTokens,
        stream: options.stream !== false
    };

    // 如果启用思考模式，添加相关参数（适用于支持的模型如 DeepSeek）
    if (options.enableThinking) {
        requestBody.stream_options = {
            include_usage: true
        };
    }

    const headers: Record<string, string> = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
    };

    try {
        const response = await fetch(url, {
            method: 'POST',
            headers,
            body: JSON.stringify(requestBody),
            signal: options.signal // 传递 AbortSignal
        });

        if (!response.ok) {
            throw new Error(`API request failed: ${response.status} ${response.statusText}`);
        }

        if (options.stream !== false && response.body) {
            await handleStreamResponse(response.body, options);
        } else {
            const data = await response.json();
            const content = data.choices?.[0]?.message?.content || '';
            options.onChunk?.(content);
            options.onComplete?.(content);
        }
    } catch (error) {
        // 检查是否是用户主动中断
        if ((error as Error).name === 'AbortError') {
            console.log('Request was aborted by user');
            options.onError?.(new Error('Request aborted'));
        } else {
            console.error('Chat error:', error);
            options.onError?.(error as Error);
        }
        throw error;
    }
}

/**
 * 发送聊天请求 (Gemini 格式)
 */
async function chatGeminiFormat(
    baseUrl: string,
    apiKey: string,
    model: string,
    options: ChatOptions
): Promise<void> {
    const url = `${baseUrl}/v1beta/models/${model}:streamGenerateContent?key=${apiKey}&alt=sse`;

    // 转换消息格式
    const contents = options.messages
        .filter(msg => msg.role !== 'system')
        .map(msg => {
            const role = msg.role === 'assistant' ? 'model' : 'user';

            // 处理多模态内容
            if (typeof msg.content === 'string') {
                return { role, parts: [{ text: msg.content }] };
            } else {
                // 转换为 Gemini 格式
                const parts = msg.content.map(part => {
                    if (part.type === 'text' && part.text) {
                        return { text: part.text };
                    } else if (part.type === 'image_url' && part.image_url) {
                        // Gemini 使用 inline_data 格式
                        const base64Data = part.image_url.url.replace(/^data:image\/\w+;base64,/, '');
                        const mimeType = part.image_url.url.match(/^data:(image\/\w+);base64,/)?.[1] || 'image/jpeg';
                        return {
                            inline_data: {
                                mime_type: mimeType,
                                data: base64Data
                            }
                        };
                    }
                    return null;
                }).filter(Boolean);

                return { role, parts };
            }
        });

    const systemInstruction = options.messages.find(msg => msg.role === 'system');

    const requestBody: any = {
        contents,
        generationConfig: {
            temperature: options.temperature || 0.7,
            maxOutputTokens: options.maxTokens
        }
    };

    // 如果启用思考模式，添加 thinkingConfig 参数
    if (options.enableThinking) {
        requestBody.generationConfig.thinkingConfig = {
            thinkingBudget: -1, // -1 表示动态思考
            includeThoughts: true // 包含思考过程
        };
    }

    if (systemInstruction) {
        requestBody.systemInstruction = {
            parts: [{ text: systemInstruction.content }]
        };
    }

    try {
        const response = await fetch(url, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(requestBody),
            signal: options.signal // 传递 AbortSignal
        });

        if (!response.ok) {
            throw new Error(`API request failed: ${response.status} ${response.statusText}`);
        }

        if (response.body) {
            await handleGeminiStreamResponse(response.body, options);
        }
    } catch (error) {
        // 检查是否是用户主动中断
        if ((error as Error).name === 'AbortError') {
            console.log('Gemini request was aborted by user');
            options.onError?.(new Error('Request aborted'));
        } else {
            console.error('Gemini chat error:', error);
            options.onError?.(error as Error);
        }
        throw error;
    }
}

/**
 * 处理 OpenAI 格式的流式响应
 */
async function handleStreamResponse(
    body: ReadableStream<Uint8Array>,
    options: ChatOptions
): Promise<void> {
    const reader = body.getReader();
    const decoder = new TextDecoder();
    let fullText = '';
    let thinkingText = '';
    let buffer = '';
    let isThinkingPhase = false;

    try {
        while (true) {
            const { done, value } = await reader.read();

            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
                const trimmed = line.trim();
                if (!trimmed || trimmed === 'data: [DONE]') continue;

                if (trimmed.startsWith('data: ')) {
                    try {
                        const json = JSON.parse(trimmed.slice(6));
                        const delta = json.choices?.[0]?.delta;

                        // 检查是否有思考内容（reasoning_content）
                        if (options.enableThinking && delta?.reasoning_content) {
                            isThinkingPhase = true;
                            thinkingText += delta.reasoning_content;
                            options.onThinkingChunk?.(delta.reasoning_content);
                        }

                        // 普通内容
                        const content = delta?.content;
                        if (content) {
                            // 如果之前在思考阶段，现在开始输出正文，说明思考结束
                            if (isThinkingPhase && options.onThinkingComplete) {
                                options.onThinkingComplete(thinkingText);
                                isThinkingPhase = false;
                            }
                            fullText += content;
                            options.onChunk?.(content);
                        }
                    } catch (e) {
                        console.error('Failed to parse SSE data:', e);
                    }
                }
            }
        }

        // 如果结束时还在思考阶段，调用思考完成回调
        if (isThinkingPhase && options.onThinkingComplete) {
            options.onThinkingComplete(thinkingText);
        }

        options.onComplete?.(fullText);
    } catch (error) {
        // 检查是否是用户主动中断
        if ((error as Error).name === 'AbortError') {
            console.log('Stream reading was aborted');
            // 如果已经有部分内容，仍然调用 onComplete
            if (fullText) {
                options.onComplete?.(fullText);
            }
            if (thinkingText && options.onThinkingComplete) {
                options.onThinkingComplete(thinkingText);
            }
        } else {
            console.error('Stream reading error:', error);
            options.onError?.(error as Error);
        }
        throw error;
    } finally {
        reader.releaseLock();
    }
}

/**
 * 处理 Gemini 格式的流式响应
 */
async function handleGeminiStreamResponse(
    body: ReadableStream<Uint8Array>,
    options: ChatOptions
): Promise<void> {
    const reader = body.getReader();
    const decoder = new TextDecoder();
    let fullText = '';
    let thinkingText = '';
    let buffer = '';
    let isThinkingPhase = false;

    try {
        while (true) {
            const { done, value } = await reader.read();

            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
                const trimmed = line.trim();
                if (!trimmed || !trimmed.startsWith('data: ')) continue;

                try {
                    const json = JSON.parse(trimmed.slice(6));
                    const parts = json.candidates?.[0]?.content?.parts;

                    if (parts && Array.isArray(parts)) {
                        for (const part of parts) {
                            if (!part.text) continue;

                            // part.thought 是布尔值，表示这个 part 是否是思考内容
                            if (options.enableThinking && part.thought === true) {
                                // 这是思考内容
                                isThinkingPhase = true;
                                thinkingText += part.text;
                                options.onThinkingChunk?.(part.text);
                            } else if (part.text) {
                                // 这是正常回复内容
                                // 如果之前在思考阶段，现在开始输出正文，说明思考结束
                                if (isThinkingPhase && options.onThinkingComplete) {
                                    options.onThinkingComplete(thinkingText);
                                    isThinkingPhase = false;
                                }
                                fullText += part.text;
                                options.onChunk?.(part.text);
                            }
                        }
                    }
                } catch (e) {
                    console.error('Failed to parse Gemini SSE data:', e);
                }
            }
        }

        // 如果结束时还在思考阶段，调用思考完成回调
        if (isThinkingPhase && options.onThinkingComplete) {
            options.onThinkingComplete(thinkingText);
        }

        options.onComplete?.(fullText);
    } catch (error) {
        // 检查是否是用户主动中断
        if ((error as Error).name === 'AbortError') {
            console.log('Gemini stream reading was aborted');
            // 如果已经有部分内容，仍然调用 onComplete
            if (fullText) {
                options.onComplete?.(fullText);
            }
            if (thinkingText && options.onThinkingComplete) {
                options.onThinkingComplete(thinkingText);
            }
        } else {
            console.error('Gemini stream reading error:', error);
            options.onError?.(error as Error);
        }
        throw error;
    } finally {
        reader.releaseLock();
    }
}

/**
 * 发送聊天请求
 */
export async function chat(
    provider: string,
    options: ChatOptions,
    customApiUrl?: string
): Promise<void> {
    // 检查是否是内置平台
    const builtInProviders: Record<string, boolean> = {
        gemini: true,
        deepseek: true,
        openai: true,
        volcano: true
    };

    let config: ProviderConfig;
    let baseUrl: string;

    if (builtInProviders[provider]) {
        // 使用内置平台配置
        config = PROVIDER_CONFIGS[provider as AIProvider];
        baseUrl = config.baseUrl;

        if (provider === 'custom' && customApiUrl) {
            const normalized = normalizeApiUrl(customApiUrl);
            baseUrl = normalized.url;
        }
    } else {
        // 自定义平台，使用OpenAI兼容格式
        if (!customApiUrl) {
            throw new Error('Custom provider requires API URL');
        }

        const normalized = normalizeApiUrl(customApiUrl);
        baseUrl = normalized.url;
        config = {
            name: 'Custom',
            baseUrl: baseUrl,
            modelsEndpoint: '/v1/models',
            chatEndpoint: '/v1/chat/completions',
            apiKeyHeader: 'Authorization'
        };
    }

    if (provider === 'gemini') {
        await chatGeminiFormat(baseUrl, options.apiKey, options.model, options);
    } else {
        await chatOpenAIFormat(baseUrl, options.apiKey, config.chatEndpoint, options);
    }
}

/**
 * 估算token数量（简单估算，1个中文字符约等于1.5个token，1个英文单词约1个token）
 */
export function estimateTokens(text: string): number {
    const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
    const englishWords = (text.match(/[a-zA-Z]+/g) || []).length;
    const otherChars = text.length - chineseChars - text.match(/[a-zA-Z\s]/g)?.length || 0;

    return Math.ceil(chineseChars * 1.5 + englishWords + otherChars * 0.5);
}

/**
 * 计算消息列表的总token数
 */
export function calculateTotalTokens(messages: Message[]): number {
    return messages.reduce((total, msg) => {
        if (typeof msg.content === 'string') {
            return total + estimateTokens(msg.content);
        } else {
            // 处理多模态内容
            return total + msg.content.reduce((sum, part) => {
                if (part.type === 'text' && part.text) {
                    return sum + estimateTokens(part.text);
                } else if (part.type === 'image_url') {
                    // 图片大约消耗85个token (根据OpenAI文档的低分辨率估算)
                    return sum + 85;
                }
                return sum;
            }, 0);
        }
    }, 0);
}
